import requests
from bs4 import BeautifulSoup
import requests
import re
from termcolor import colored
from time import sleep

class ShodanScraper:
    def __init__(self, query, proxies):
        self.query = query
        self.proxies = proxies


    def veryfiy_page(self, response):
        if response.status_code != 200:
            print(colored("Error: Response code: {}".format(response.status_code), "red"))
            return False
        elif "Daily search usage limit reached" in response.text:
            print(colored("Daily search usage limit reached", "yellow"))
            return "Somewhat working"
        elif "Please create a" in response.text:
            print(colored("Please create an account to view more results.", "yellow"))
            return False
        elif "Result limit reached." in response.text:
            print(colored("Result limit reached.", "yellow"))
            return False
        else:
            return True
    

    def search_shodan(self, process_index, page_index=1, ):
        self.page_index = page_index
        self.process_index = process_index
        #loop through pages

        while True:
            try:
                page = self.page_index
                query = self.query + '&page=' + str(page)
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'
                    }
                url = f'http://www.shodan.io/search?query={query}'
                proxy = self.proxies.get_proxies()
                print(f"[ {process_index} ]"+colored(f"Searching Shodan for: {query}, using proxy: {proxy}", "blue"))
                response = requests.get(url, proxies=proxy,headers=headers, timeout=10)
                soup = BeautifulSoup(response.text, 'html.parser')
                proxy_string = str(proxy["http"][7:])
                veryfication = self.veryfiy_page(response)
                if veryfication != True:
                    # print("Error, switching proxy")
                    continue
                
                print(soup.prettify())

                found_ips = []
                for div in soup.find_all("div", class_="heading"):
                    a = div.find("a", class_="title text-dark")
                    if a:
                        ip = a['href'][6:]
                        found_ips.append(ip) 
                if len(found_ips) == 0:
                    #print("No IP addresses found for query: {}".format(query))
                    pass
                else:
                    print(colored("IP addresses found for query: {}".format(query)+" found with proxy "+str(proxy_string), "green"))
                    print(colored(found_ips, "green"))
                    filename = str(self.query) + "_ips.txt"
                    with open(filename, "a") as file:
                        pass
                    for ip in found_ips:
                        if ip not in open(filename).read():
                            with open(filename, "a") as file:
                                file.write(ip + "\n")
                    if page >= self.page_index:
                        self.page_index += 1
                    sleep(5)
                    with open("working_proxies.txt", "a") as file:
                        pass
                    if proxy_string not in open("working_proxies.txt").read():
                        with open("working_proxies.txt", "a") as file:
                            file.write(str(proxy_string) + "\n")
                sleep(1)
                continue
            except KeyboardInterrupt:
                return print(colored("Exiting", "red"))
            except Exception as e:
                #print(e)
                continue


    def get_ips(self, process_index="+"):
        try:
            for ip in self.search_shodan(process_index) or []:
                print(ip)
                filename = str(self.query) + "_ips.txt"
                # if filename doesnt exist, create it
                with open(filename, "a") as file:
                    pass
                # Code to execute if IP is in proper format and not in file
                if re.match(r"\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}$", ip) and ip not in open(filename).read():
                    with open(filename, "a") as file:
                        file.write(ip + "\n")
        except Exception as e:
            return print(e)

    def get_CVEs(self, exploitdb):
        filename = str(self.query) + "_ips.txt"
        #check for file existence
        try:
            with open(filename, "r") as file:
                pass
        except FileNotFoundError:
            return print("File not found")

        with open(filename, "r") as file:
            headers = {
                    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'
                    }
            for ip in file:
                ip = ip.strip()
                print(ip)
                url = str("https://internetdb.shodan.io/"+ip)
                print(url)
                print("Searching CVE's for: {}".format(ip))
                try:
                    # Get response from Shodan API
                    response = requests.get(url).json()
                    #print(response)
                    cve_list = response["vulns"]

                    # Print scraped CVE's
                    print("CVE's found for IP address {}:".format(ip))
                    if len(cve_list) > 0:
                        print(colored(cve_list, "green"))
                    else:
                        print(colored(f"No CVE's found for IP address: {ip} :(", "red"))
                    # Search for exploits in ExploitDB
                    print(colored("Searching ExploitDB for exploits...", "light_magenta"))
                    for cve in cve_list:
                        result = exploitdb.search(cve)
                        if result != []:
                            print(f"{cve} found in ExploitDB")
                            print(colored(result, "green"))
                            for exploit in result:
                                print(exploit.link)
                except Exception as e:
                    return print(e)
                